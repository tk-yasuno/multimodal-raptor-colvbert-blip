"""
RAPTOR Treeå¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
NetworkXã¨Matplotlibã‚’ä½¿ç”¨ã—ã¦ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’å¯è¦–åŒ–

ä¿å­˜ã•ã‚ŒãŸscaling_test_tree_*.pklãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰RAPTOR Treeã‚’èª­ã¿è¾¼ã¿ã€
éšå±¤æ§‹é€ ã‚’è¦–è¦šåŒ–ã—ã¦PNG/PDFã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
"""

import os
import sys
import pickle
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib
from pathlib import Path
from typing import Dict, List, Tuple, Any
import numpy as np
from datetime import datetime
import re
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer

# UTF-8å‡ºåŠ›è¨­å®šï¼ˆWindowså¯¾å¿œï¼‰
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
matplotlib.rcParams['font.family'] = ['MS Gothic', 'Yu Gothic', 'Meiryo', 'DejaVu Sans']
matplotlib.rcParams['axes.unicode_minus'] = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), '0_base_tsunami-lesson-rag'))


class RAPTORTreeVisualizer:
    """RAPTOR Treeã®å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, tree_path: str):
        """
        Args:
            tree_path: RAPTORãƒ„ãƒªãƒ¼ã®pickleãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.tree_path = Path(tree_path)
        self.tree = None
        self.graph = None
        self.node_depths = {}
        self.node_types = {}  # 'leaf' or 'internal'
        self.node_keywords = {}  # ãƒãƒ¼ãƒ‰ã”ã¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.all_summaries = []  # TF-IDFè¨ˆç®—ç”¨ã®å…¨ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
        self.node_to_summary_idx = {}  # ãƒãƒ¼ãƒ‰IDã‹ã‚‰ã‚µãƒãƒªãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    
    def extract_keywords_tfidf(self, texts: List[str], top_n: int = 3) -> List[List[str]]:
        """
        TF-IDFã‚’ä½¿ç”¨ã—ã¦å„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        
        Args:
            texts: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            top_n: å„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŠ½å‡ºã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°
        
        Returns:
            å„ãƒ†ã‚­ã‚¹ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        if not texts or len(texts) == 0:
            return []
        
        # TF-IDFãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼è¨­å®š
        # token_pattern: æ—¥æœ¬èªï¼ˆ2æ–‡å­—ä»¥ä¸Šï¼‰ã¨è‹±èªï¼ˆ3æ–‡å­—ä»¥ä¸Šï¼‰ã‚’ãƒãƒƒãƒ
        vectorizer = TfidfVectorizer(
            token_pattern=r'[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ¶ãƒ¼]{2,}|[a-zA-Z]{3,}',
            max_features=1000,
            stop_words=None
        )
        
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨
        stop_words = {'ã“ã¨', 'ã‚‚ã®', 'ãŸã‚', 'ã‚ˆã†', 'ã¨ã“ã‚', 'ã“ã‚Œ', 'ãã‚Œ', 
                     'ã‚ã‚Œ', 'ã“ã®', 'ãã®', 'ã‚ã®', 'ãªã©', 'ã»ã‹', 'ä»¥ä¸Š',
                     'ã«ã¤ã„ã¦', 'ã«ãŠã‘ã‚‹', 'ã«é–¢ã™ã‚‹', 'ã«ã‚ˆã‚‹', 'ã«ã‚ˆã£ã¦',
                     'ã¨ã—ã¦', 'ã¨ã™ã‚‹', 'ã§ã‚ã‚‹', 'ã§ã™', 'ã¾ã™', 'ã—ãŸ'}
        
        try:
            # TF-IDFè¡Œåˆ—ã‚’è¨ˆç®—
            tfidf_matrix = vectorizer.fit_transform(texts)
            feature_names = vectorizer.get_feature_names_out()
            
            # å„ãƒ†ã‚­ã‚¹ãƒˆã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            all_keywords = []
            for i in range(len(texts)):
                # iç•ªç›®ã®ãƒ†ã‚­ã‚¹ãƒˆã®TF-IDFã‚¹ã‚³ã‚¢ã‚’å–å¾—
                tfidf_scores = tfidf_matrix[i].toarray()[0]
                
                # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
                top_indices = tfidf_scores.argsort()[::-1]
                
                # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤å¤–ã—ãªãŒã‚‰ä¸Šä½Nå€‹ã‚’å–å¾—
                keywords = []
                for idx in top_indices:
                    if len(keywords) >= top_n:
                        break
                    word = feature_names[idx]
                    if word not in stop_words and tfidf_scores[idx] > 0:
                        keywords.append(word)
                
                all_keywords.append(keywords)
            
            return all_keywords
            
        except Exception as e:
            print(f"âš ï¸ TF-IDFæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
            return [[] for _ in texts]
        
    def load_tree(self):
        """Pickleãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ„ãƒªãƒ¼ã‚’èª­ã¿è¾¼ã¿"""
        print(f"ğŸ“‚ ãƒ„ãƒªãƒ¼èª­ã¿è¾¼ã¿ä¸­: {self.tree_path.name}")
        
        with open(self.tree_path, 'rb') as f:
            data = pickle.load(f)
        
        # è¾æ›¸å½¢å¼ã®å ´åˆã€'tree'ã‚­ãƒ¼ã‹ã‚‰ãƒ„ãƒªãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å–å¾—
        if isinstance(data, dict) and 'tree' in data:
            self.tree = data['tree']
            print(f"âœ… ãƒ„ãƒªãƒ¼èª­ã¿è¾¼ã¿å®Œäº†ï¼ˆè¾æ›¸å½¢å¼ï¼‰")
        else:
            self.tree = data
            print(f"âœ… ãƒ„ãƒªãƒ¼èª­ã¿è¾¼ã¿å®Œäº†")
        
        return self.tree
    
    def build_graph(self):
        """NetworkXã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
        print("ğŸ”¨ NetworkXã‚°ãƒ©ãƒ•æ§‹ç¯‰ä¸­...")
        
        self.graph = nx.DiGraph()
        
        # ãƒãƒ¼ãƒ‰ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        self.node_counter = 0
        self.leaf_nodes = []
        self.internal_nodes = []
        
        # ç¬¬1ãƒ‘ã‚¹: å…¨ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†
        temp_nodes = []  # (node_id, cluster_id, summary_text, depth, parent_id, has_children) ã®ãƒªã‚¹ãƒˆ
        
        def get_node_id():
            """ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒãƒ¼ãƒ‰IDã‚’ç”Ÿæˆ"""
            self.node_counter += 1
            return f"node_{self.node_counter}"
        
        def collect_summaries(tree_dict, depth=0, parent_id=None):
            """
            ç¬¬1ãƒ‘ã‚¹: ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†
            """
            if not isinstance(tree_dict, dict):
                return
            
            if 'clusters' in tree_dict and tree_dict['clusters']:
                clusters = tree_dict['clusters']
                
                for cluster_id, cluster_data in clusters.items():
                    # ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                    summary_text = ""
                    if 'summary' in cluster_data:
                        summary = cluster_data['summary']
                        if hasattr(summary, 'page_content'):
                            summary_text = summary.page_content
                        elif isinstance(summary, dict):
                            summary_text = summary.get('page_content', summary.get('text', ''))
                    
                    # å­ã®æœ‰ç„¡åˆ¤å®š
                    has_children = ('children' in cluster_data and 
                                  cluster_data['children'] and 
                                  'clusters' in cluster_data['children'] and
                                  cluster_data['children']['clusters'])
                    
                    # ãƒãƒ¼ãƒ‰IDç”Ÿæˆ
                    node_id = get_node_id()
                    
                    # æƒ…å ±ã‚’ä¿å­˜
                    temp_nodes.append({
                        'node_id': node_id,
                        'cluster_id': cluster_id,
                        'summary_text': summary_text,
                        'depth': depth,
                        'parent_id': parent_id,
                        'has_children': has_children
                    })
                    
                    # ã‚µãƒãƒªãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    self.all_summaries.append(summary_text if summary_text else "")
                    self.node_to_summary_idx[node_id] = len(self.all_summaries) - 1
                    
                    # å­ãƒ„ãƒªãƒ¼ã‚’å†å¸°çš„ã«å‡¦ç†
                    if has_children:
                        collect_summaries(
                            cluster_data['children'],
                            depth + 1,
                            node_id
                        )
        
        # ç¬¬1ãƒ‘ã‚¹å®Ÿè¡Œ: ã‚µãƒãƒªãƒ¼åé›†
        if isinstance(self.tree, dict):
            collect_summaries(self.tree)
        else:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒ„ãƒªãƒ¼ãŒè¾æ›¸å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
            return None
        
        print(f"   ç¬¬1ãƒ‘ã‚¹å®Œäº†: {len(self.all_summaries)}å€‹ã®ã‚µãƒãƒªãƒ¼ã‚’åé›†")
        
        # ç¬¬2ãƒ‘ã‚¹: TF-IDFã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        if len(self.all_summaries) > 0:
            print("   TF-IDFã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºä¸­...")
            all_keywords = self.extract_keywords_tfidf(self.all_summaries, top_n=3)
        else:
            all_keywords = []
        
        # ç¬¬3ãƒ‘ã‚¹: ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        print("   ã‚°ãƒ©ãƒ•ãƒãƒ¼ãƒ‰ä½œæˆä¸­...")
        for node_info in temp_nodes:
            node_id = node_info['node_id']
            cluster_id = node_info['cluster_id']
            summary_text = node_info['summary_text']
            depth = node_info['depth']
            parent_id = node_info['parent_id']
            has_children = node_info['has_children']
            
            # TF-IDFã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—
            summary_idx = self.node_to_summary_idx[node_id]
            keywords = all_keywords[summary_idx] if summary_idx < len(all_keywords) else []
            
            self.node_keywords[node_id] = keywords
            
            # ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¤å®š
            node_type = 'internal' if has_children else 'leaf'
            
            if node_type == 'leaf':
                self.leaf_nodes.append(node_id)
            else:
                self.internal_nodes.append(node_id)
            
            self.node_types[node_id] = node_type
            self.node_depths[node_id] = depth
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«ä½œæˆï¼ˆã‚ˆã‚Šã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ï¼‰
            if keywords:
                # æœ€ã‚‚é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1ã¤ã®ã¿ã€ã¾ãŸã¯2ã¤ã‚’æ”¹è¡Œã§åŒºåˆ‡ã‚‹
                if len(keywords) >= 2:
                    keyword_label = f"{keywords[0]}\n{keywords[1]}"
                else:
                    keyword_label = keywords[0]
            else:
                keyword_label = f"C{cluster_id}"
            
            self.graph.add_node(
                node_id,
                depth=depth,
                text=str(summary_text[:100]) if summary_text else "",
                keywords=keywords,
                node_type=node_type,
                label=keyword_label
            )
            
            # è¦ªãƒãƒ¼ãƒ‰ã¨ã®æ¥ç¶š
            if parent_id:
                self.graph.add_edge(parent_id, node_id)
        
        if self.graph.number_of_nodes() == 0:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ãƒãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return None
        
        print(f"âœ… ã‚°ãƒ©ãƒ•æ§‹ç¯‰å®Œäº†")
        print(f"   ç·ãƒãƒ¼ãƒ‰æ•°: {self.graph.number_of_nodes()}")
        print(f"   ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {len(self.leaf_nodes)}")
        print(f"   å†…éƒ¨ãƒãƒ¼ãƒ‰: {len(self.internal_nodes)}")
        print(f"   ã‚¨ãƒƒã‚¸æ•°: {self.graph.number_of_edges()}")
        print(f"   æœ€å¤§æ·±åº¦: {max(self.node_depths.values()) if self.node_depths else 0}")
        
        return self.graph
    
    def visualize_tree(self, output_path: str, figsize: Tuple[int, int] = None, dpi: int = 150):
        """
        ãƒ„ãƒªãƒ¼ã‚’å¯è¦–åŒ–ã—ã¦ä¿å­˜
        
        Args:
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆPNG/PDFï¼‰
            figsize: å›³ã®ã‚µã‚¤ã‚ºï¼ˆå¹…ã€é«˜ã•ï¼‰ã€‚Noneã®å ´åˆã¯ãƒãƒ¼ãƒ‰æ•°ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´
            dpi: è§£åƒåº¦
        """
        if self.graph is None:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ã‚°ãƒ©ãƒ•ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«build_graph()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print(f"ğŸ¨ ãƒ„ãƒªãƒ¼å¯è¦–åŒ–ä¸­...")
        
        # ãƒãƒ¼ãƒ‰æ•°ã«å¿œã˜ã¦å›³ã®ã‚µã‚¤ã‚ºã‚’è‡ªå‹•èª¿æ•´
        if figsize is None:
            total_nodes = self.graph.number_of_nodes()
            if total_nodes > 30:
                figsize = (28, 14)  # å¤§ããªãƒ„ãƒªãƒ¼
            elif total_nodes > 20:
                figsize = (24, 12)  # ä¸­è¦æ¨¡ãƒ„ãƒªãƒ¼
            else:
                figsize = (20, 10)  # å°è¦æ¨¡ãƒ„ãƒªãƒ¼
        
        # å›³ã¨ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)
        
        # éšå±¤ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
        pos = self._compute_hierarchical_layout()
        
        # ãƒãƒ¼ãƒ‰ã®è‰²è¨­å®š
        node_colors = []
        for node in self.graph.nodes():
            if self.node_types[node] == 'leaf':
                node_colors.append('#90EE90')  # ãƒ©ã‚¤ãƒˆã‚°ãƒªãƒ¼ãƒ³ï¼ˆãƒªãƒ¼ãƒ•ï¼‰
            else:
                depth = self.node_depths[node]
                # æ·±ã•ã«å¿œã˜ã¦è‰²ã‚’å¤‰åŒ–ï¼ˆé’ç³»ã®ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
                intensity = 1.0 - (depth * 0.3)
                node_colors.append((0.3, 0.5, intensity))
        
        # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºè¨­å®šï¼ˆã‚ˆã‚Šã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ï¼‰
        node_sizes = []
        for node in self.graph.nodes():
            if self.node_types[node] == 'leaf':
                node_sizes.append(500)  # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ã‚’å°‘ã—å¤§ãã
            else:
                depth = self.node_depths[node]
                size = 1000 + (depth * 300)  # å†…éƒ¨ãƒãƒ¼ãƒ‰ã‚‚èª¿æ•´
                node_sizes.append(size)
        
        # ã‚¨ãƒƒã‚¸æç”»
        nx.draw_networkx_edges(
            self.graph, pos, ax=ax,
            edge_color='gray',
            alpha=0.5,
            arrows=True,
            arrowsize=15,
            width=1.5,
            connectionstyle='arc3,rad=0.1'
        )
        
        # ãƒãƒ¼ãƒ‰æç”»
        nx.draw_networkx_nodes(
            self.graph, pos, ax=ax,
            node_color=node_colors,
            node_size=node_sizes,
            alpha=0.9,
            edgecolors='black',
            linewidths=2
        )
        
        # ãƒ©ãƒ™ãƒ«æç”»ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¡¨ç¤ºï¼‰
        labels = nx.get_node_attributes(self.graph, 'label')
        
        # ãƒ©ãƒ™ãƒ«ä½ç½®ã‚’ãƒãƒ¼ãƒ‰ã®å°‘ã—ä¸‹ã«èª¿æ•´
        label_pos = {}
        y_offset = 0.08  # Yè»¸æ–¹å‘ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆãƒãƒ¼ãƒ‰ã®ä¸‹ã«é…ç½®ï¼‰
        for node, (x, y) in pos.items():
            label_pos[node] = (x, y - y_offset)
        
        # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼ˆãƒãƒ¼ãƒ‰æ•°ã«å¿œã˜ã¦ï¼‰
        total_nodes = self.graph.number_of_nodes()
        if total_nodes > 50:
            font_size = 5
        elif total_nodes > 30:
            font_size = 6
        elif total_nodes > 20:
            font_size = 7
        else:
            font_size = 8
        
        nx.draw_networkx_labels(
            self.graph, label_pos, labels, ax=ax,
            font_size=font_size,
            font_weight='bold',
            font_family='MS Gothic',
            bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='gray', alpha=0.85)
        )
        
        # ã‚¿ã‚¤ãƒˆãƒ«è¨­å®š
        tree_name = self.tree_path.stem
        total_nodes = self.graph.number_of_nodes()
        max_depth = max(self.node_depths.values()) + 1
        leaf_count = sum(1 for t in self.node_types.values() if t == 'leaf')
        internal_count = total_nodes - leaf_count
        
        ax.set_title(
            f"RAPTOR Tree: {tree_name}\n"
            f"Total Nodes: {total_nodes} (Leaf: {leaf_count}, Internal: {internal_count}) | "
            f"Max Depth: {max_depth}",
            fontsize=14,
            fontweight='bold',
            pad=20
        )
        
        # å‡¡ä¾‹è¿½åŠ 
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#90EE90', edgecolor='black', label='ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ (Depth 0)'),
            Patch(facecolor=(0.3, 0.5, 0.7), edgecolor='black', label='å†…éƒ¨ãƒãƒ¼ãƒ‰ (Depth 1+)')
        ]
        ax.legend(handles=legend_elements, loc='upper right', fontsize=10)
        
        ax.axis('off')
        plt.tight_layout()
        
        # ä¿å­˜
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_path, dpi=dpi, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… å¯è¦–åŒ–å®Œäº†: {output_path}")
        print(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / 1024:.1f} KB")
    
    def _compute_hierarchical_layout(self) -> Dict[str, Tuple[float, float]]:
        """éšå±¤ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è¨ˆç®—ï¼ˆãƒ©ãƒ™ãƒ«é‡è¤‡ã‚’é˜²ãï¼‰"""
        pos = {}
        
        # æ·±åº¦ã”ã¨ã«ãƒãƒ¼ãƒ‰ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        depth_groups = {}
        for node, depth in self.node_depths.items():
            if depth not in depth_groups:
                depth_groups[depth] = []
            depth_groups[depth].append(node)
        
        max_depth = max(self.node_depths.values())
        
        # å„æ·±åº¦ã§å¿…è¦ãªæœ€å°å¹…ã‚’è¨ˆç®—
        # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ãŒå¤šã„å ´åˆã¯å¹…ã‚’åºƒã’ã‚‹
        max_nodes_in_depth = max(len(nodes) for nodes in depth_groups.values())
        
        # ãƒ©ãƒ™ãƒ«ã®é‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã®æœ€å°é–“éš”ã‚’è¨­å®š
        # ãƒãƒ¼ãƒ‰æ•°ãŒå¤šã„ã»ã©åºƒã„ç¯„å›²ã«é…ç½®
        if max_nodes_in_depth > 15:
            x_margin = 0.02
            x_range = (0.01, 0.99)
        elif max_nodes_in_depth > 10:
            x_margin = 0.05
            x_range = (0.03, 0.97)
        else:
            x_margin = 0.1
            x_range = (0.05, 0.95)
        
        # å„æ·±åº¦ã®ãƒãƒ¼ãƒ‰ã‚’é…ç½®
        for depth, nodes in depth_groups.items():
            y = max_depth - depth  # ä¸Šã‹ã‚‰ä¸‹ã¸ï¼ˆãƒ«ãƒ¼ãƒˆãŒä¸Šï¼‰
            n = len(nodes)
            
            # Xåº§æ¨™ã‚’å‡ç­‰é…ç½®ï¼ˆåºƒã„ç¯„å›²ã§ï¼‰
            if n == 1:
                x_coords = [0.5]
            else:
                x_coords = np.linspace(x_range[0], x_range[1], n)
            
            for i, node in enumerate(nodes):
                pos[node] = (x_coords[i], y)
        
        return pos
    
    def create_statistics_plot(self, output_path: str):
        """ãƒ„ãƒªãƒ¼çµ±è¨ˆã®ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        print("ğŸ“Š çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆä½œæˆä¸­...")
        
        # æ·±åº¦ã”ã¨ã®ãƒãƒ¼ãƒ‰æ•°é›†è¨ˆ
        depth_counts = {}
        for node, depth in self.node_depths.items():
            depth_counts[depth] = depth_counts.get(depth, 0) + 1
        
        depths = sorted(depth_counts.keys())
        counts = [depth_counts[d] for d in depths]
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5), dpi=100)
        
        # 1. æ·±åº¦åˆ¥ãƒãƒ¼ãƒ‰æ•°
        colors = plt.cm.viridis(np.linspace(0, 1, len(depths)))
        ax1.bar(depths, counts, color=colors, edgecolor='black', linewidth=1.5)
        ax1.set_xlabel('æ·±åº¦ (Depth)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('ãƒãƒ¼ãƒ‰æ•°', fontsize=12, fontweight='bold')
        ax1.set_title('æ·±åº¦åˆ¥ãƒãƒ¼ãƒ‰æ•°', fontsize=14, fontweight='bold')
        ax1.grid(axis='y', alpha=0.3)
        
        # å€¤ã‚’æ£’ã‚°ãƒ©ãƒ•ä¸Šã«è¡¨ç¤º
        for i, (d, c) in enumerate(zip(depths, counts)):
            ax1.text(d, c + max(counts)*0.02, str(c), ha='center', va='bottom', fontweight='bold')
        
        # 2. ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚µãƒãƒªãƒ¼
        total_nodes = sum(counts)
        leaf_nodes = counts[0] if 0 in depth_counts else 0
        internal_nodes = total_nodes - leaf_nodes
        max_depth = max(depths)
        avg_branching = internal_nodes / max(1, max_depth)
        
        stats_text = (
            f"ç·ãƒãƒ¼ãƒ‰æ•°: {total_nodes}\n"
            f"ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰: {leaf_nodes}\n"
            f"å†…éƒ¨ãƒãƒ¼ãƒ‰: {internal_nodes}\n"
            f"æœ€å¤§æ·±åº¦: {max_depth}\n"
            f"å¹³å‡åˆ†å²æ•°: {avg_branching:.2f}\n"
            f"ãƒªãƒ¼ãƒ•æ¯”ç‡: {leaf_nodes/total_nodes*100:.1f}%"
        )
        
        ax2.text(0.5, 0.5, stats_text, 
                 ha='center', va='center',
                 fontsize=14,
                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                 family='MS Gothic')
        ax2.axis('off')
        ax2.set_title('ãƒ„ãƒªãƒ¼çµ±è¨ˆã‚µãƒãƒªãƒ¼', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜
        output_path = Path(output_path)
        plt.savefig(output_path, dpi=100, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {output_path}")


def visualize_all_trees(
    pkl_dir: str,
    output_dir: str,
    pattern: str = "scaling_test_tree_*.pkl"
):
    """
    æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨RAPTORãƒ„ãƒªãƒ¼ã‚’å¯è¦–åŒ–
    
    Args:
        pkl_dir: pklãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        output_dir: å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        pattern: ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³
    """
    pkl_dir = Path(pkl_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # pklãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pkl_files = list(pkl_dir.glob(pattern))
    
    if not pkl_files:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {pkl_dir} ã« {pattern} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print("=" * 80)
    print("RAPTOR Tree å¯è¦–åŒ–")
    print(f"æ¤œå‡ºãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(pkl_files)}")
    print("=" * 80)
    
    for i, pkl_file in enumerate(sorted(pkl_files), 1):
        print(f"\n[{i}/{len(pkl_files)}] å‡¦ç†ä¸­: {pkl_file.name}")
        print("-" * 80)
        
        try:
            # å¯è¦–åŒ–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
            visualizer = RAPTORTreeVisualizer(pkl_file)
            
            # ãƒ„ãƒªãƒ¼èª­ã¿è¾¼ã¿
            visualizer.load_tree()
            
            # ã‚°ãƒ©ãƒ•æ§‹ç¯‰
            visualizer.build_graph()
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
            base_name = pkl_file.stem
            tree_png = output_dir / f"{base_name}_tree.png"
            stats_png = output_dir / f"{base_name}_stats.png"
            
            # ãƒ„ãƒªãƒ¼å›³ä½œæˆ
            visualizer.visualize_tree(tree_png, figsize=(24, 14), dpi=150)
            
            # çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
            visualizer.create_statistics_plot(stats_png)
            
            print(f"âœ… [{i}/{len(pkl_files)}] å®Œäº†\n")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {pkl_file.name} ã®å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            print(f"   è©³ç´°: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    print("\n" + "=" * 80)
    print("âœ… å…¨ã¦ã®å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"ğŸ“‚ å‡ºåŠ›å…ˆ: {output_dir}")
    print("=" * 80)


if __name__ == "__main__":
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹è¨­å®š
    pkl_dir = r"C:\Users\yasun\LangChain\learning-langchain\multimodal-raptor-colvbert-blip\data\encoder_comparison_46pdfs\results"
    output_dir = r"C:\Users\yasun\LangChain\learning-langchain\multimodal-raptor-colvbert-blip\data\encoder_comparison_46pdfs\raptor_trees"
    
    # å…¨ãƒ„ãƒªãƒ¼ã‚’å¯è¦–åŒ–
    visualize_all_trees(
        pkl_dir=pkl_dir,
        output_dir=output_dir,
        pattern="scaling_test_tree_*.pkl"
    )
